use serde::{Serialize, Deserialize};
use crate::openai::Role;

/// ChatRequest represents a chat completion request.
#[derive(Default, Serialize, Deserialize)]
pub struct ChatRequest {

    /// The model ID to use.
    pub model: String,

    /// A list of messages comprising the conversation so far.
    #[serde(skip_serializing_if = "Vec::is_empty")]
    pub messages: Vec<Message>,

    /// A list of tools that the model may call.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tools: Option<Vec<ToolDefinition>>,

    /// Enable thinking mode (available only for thinking models).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub think: Option<bool>,

    /// Keep model alive for the specified duration.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub keep_alive: Option<f64>,

    /// Whether to stream the response.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub stream: Option<bool>,
}

impl ChatRequest {

    /// Creates a [ChatRequest] from a single text prompt.
    pub fn from_prompt(model: &str, prompt: &str) -> Self {
        let mut req = Self::default();
        req.model = model.to_string();
        req.messages = vec![Message {
            role: Role::User,
            content: Some(prompt.to_string()),
            tool_calls: None,
            images: None,
            thinking: None,
        }];
        req
    }

    /// Creates a [ChatRequest] from a vector of messages.
    pub fn from_messages(model: &str, messages: Vec<Message>) -> Self {
        let mut req = Self::default();
        req.model = model.to_string();
        req.messages = messages;
        req
    }

    /// Populates the [Self::tools] field with the given value.
    pub fn with_tools(self, tools: Option<Vec<ToolDefinition>>) -> Self {
        Self { tools, ..self }
    }

    /// Populates the [Self::think] field with the given value.
    pub fn with_think(self, think: Option<bool>) -> Self {
        Self { think, ..self }
    }

    /// Populates the [Self::keep_alive] field with the given value.
    pub fn with_keep_alive(self, keep_alive: Option<f64>) -> Self {
        Self { keep_alive, ..self }
    }

    /// Populates the [Self::stream] field with the given value.
    pub fn with_stream(self, stream: Option<bool>) -> Self {
        Self { stream, ..self }
    }
}

/// Tool definition.
#[derive(Serialize, Deserialize)]
pub struct ToolDefinition {

    /// The tool type (currently only 'function' is supported).
    #[serde(rename = "type")]
    pub kind: Option<String>,

    /// Tool function definition.
    pub function: FunctionDefinition,
}

/// Function Definition.
#[derive(Serialize, Deserialize)]
pub struct FunctionDefinition {

    /// The name of the function to be called. Must be a-z, A-Z, 0-9,
    /// or contain underscores and dashes, with a maximum length of
    /// 64.
    pub name: String,

    /// A description of what the function does, used by the model to
    /// choose when and how to call the function.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub description: Option<String>,

    /// The parameters the functions accepts.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub parameters: Option<serde_json::Value>,

    /// Whether to enable strict schema adherence when generating the
    /// function call. If set to true, the model will follow the exact
    /// schema defined in the `parameters` field.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub strict: Option<bool>,
}

/// Chat message.
#[derive(Debug, Serialize, Deserialize)]
pub struct Message {

    /// The role of the messages author.
    pub role: Role,

    /// The contents of the message.
    pub content: Option<String>,

    /// The tool calls generated by the model, such as function calls.
    ///
    /// Only specified in `assistant` responses that use tool calls.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tool_calls: Option<Vec<ToolCall>>,

    /// Image inputs.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub images: Option<Vec<String>>,

    /// Thinking text traces (only for thinking models).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub thinking: Option<String>,

}

#[derive(Debug, Serialize, Deserialize)]
pub struct ToolCall {

    /// The function that the model called.
    pub function: FunctionCall,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct FunctionCall {

    /// The arguments to call the function with.
    ///
    /// Note that the model does not always generate valid JSON, and
    /// may hallucinate parameters not defined by your function
    /// schema. Validate the arguments in your code before calling
    /// your function.
    pub arguments: serde_json::Value,

    /// The name of the function to call.
    pub name: String,
}

/// A response to a completion request.
#[derive(Debug, Serialize, Deserialize)]
pub struct ChatResponse {

    /// The model that responded to the request.
    pub model: String,

    /// The response message.
    pub message: Message,

    /// The reason the LLM was terminated.
    pub done_reason: Option<String>,

    /// Whether the model is done responding to the request.
    pub done: bool,

    /// Tokens in the prompt.
    pub prompt_eval_count: Option<i64>,

    /// Total token count.
    pub eval_count: Option<i64>,
}
